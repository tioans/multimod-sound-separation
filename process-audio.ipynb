{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4da5bff-15c1-4553-a69b-a910c04c5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os, logging\n",
    "import numpy as np\n",
    "\n",
    "import torch as th\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0958a9df-59d1-4c32-99c5-a53de5e096be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Dir:  /scratch/IOSZ/waveformer/multimod-sound-separation\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "print(\"Root Dir: \", ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9df3b9fc-0a12-4e00-8d3f-9770e28a789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose input, output and target\n",
    "INPUT_PATH = \"Sample.wav\"\n",
    "OUTPUT_PATH = \"sample-extract.wav\"\n",
    "TARGET = \"Computer keyboard\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ba6aa-6cb2-4f5a-bf9b-4422d490014b",
   "metadata": {},
   "source": [
    "# ImageBind embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07e24e31-cb95-431f-8ef0-1e87df45cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir:  /scratch/IOSZ/waveformer/multimod-sound-separation/imagebind\n"
     ]
    }
   ],
   "source": [
    "# change the current path to the imagebind root\n",
    "os.chdir(os.path.join(os.getcwd(), \"imagebind\"))\n",
    "print(\"Dir: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b286e6-181e-408e-bdfb-eed30f4ea76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iosz/.conda/envs/waveformer/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "from imagebind.models import imagebind_model\n",
    "from imagebind.models.imagebind_model import ModalityType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de1679c7-0797-41ad-994d-6679b6a7a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list=[TARGET]\n",
    "audio_paths=[INPUT_PATH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c351cf88-8ce9-43d8-b5a1-2b19f50b1791",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if th.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Instantiate model\n",
    "model = imagebind_model.imagebind_huge(pretrained=True)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Load data\n",
    "inputs = {\n",
    "    ModalityType.TEXT: data.load_and_transform_text(text_list, device),\n",
    "    # ModalityType.VISION: data.load_and_transform_vision_data(image_paths, device),\n",
    "    ModalityType.AUDIO: data.load_and_transform_audio_data(audio_paths, device),\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    embeddings = model(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b175c2-6f3a-4ba1-8e18-6b4605f82584",
   "metadata": {},
   "source": [
    "# Waveformer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a645cc5c-af9a-494e-bdbb-4e39e7358295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir:  /scratch/IOSZ/waveformer/multimod-sound-separation/multimod-waveformer\n"
     ]
    }
   ],
   "source": [
    "# change the current path to the imagebind root\n",
    "os.chdir(os.path.join(ROOT_DIR, \"multimod-waveformer\"))\n",
    "print(\"Dir: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46010506-e279-430a-8ce0-d4160d6663d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iosz/.conda/envs/waveformer/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/iosz/.conda/envs/waveformer/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "/home/iosz/.conda/envs/waveformer/lib/python3.8/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/home/iosz/.conda/envs/waveformer/lib/python3.8/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.helpers import utils\n",
    "from src.training.dcc_tf import Net as Waveformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "454163c5-14d5-48ed-87e5-ca4ce52b69dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/IOSZ/waveformer/multimod-sound-separation/multimod-waveformer/experiments/dcc_tf_ckpt_E256_10_D128_1/config.json'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.getcwd(), \"experiments\", \"dcc_tf_ckpt_E256_10_D128_1\", \"140.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e50e47-df9e-47fa-aa91-4383e817d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config file\n",
    "params = utils.Params(os.path.join(os.getcwd(), \"experiments\", \"dcc_tf_ckpt_E256_10_D128_1\", \"config.json\"))\n",
    "model = Waveformer(**params.model_params)\n",
    "\n",
    "# Instantiate waveformer and load pretrained weights\n",
    "model.load_state_dict(\n",
    "    th.load(os.path.join(os.getcwd(), \"experiments\", \"dcc_tf_ckpt_E256_10_D128_1\", \"141.pt\"), \n",
    "            map_location=device)[\"model_state_dict\"]\n",
    "    )\n",
    "\n",
    "model.to(device).eval()\n",
    "\n",
    "# Read input audio\n",
    "mixture, fs = torchaudio.load(args.input)\n",
    "\n",
    "if fs != 44100:\n",
    "    mixture = torchaudio.functional.resample(mixture, orig_freq=fs, new_freq=44100)\n",
    "mixture = mixture.unsqueeze(0).to(device)\n",
    "print(\"Loaded input audio from %s\" % args.input)\n",
    "\n",
    "# get the query from imagebind\n",
    "query = embeddings[ModalityType.TEXT]\n",
    "\n",
    "# run inference\n",
    "with th.inference_mode():\n",
    "        output = model(mixture.to(device), query.to(device)).squeeze(0).cpu()\n",
    "    if fs != 44100:\n",
    "        output = torchaudio.functional.resample(output, orig_freq=44100, new_freq=fs)\n",
    "    print(\"Inference done. Saving output audio to %s\" % args.output)\n",
    "\n",
    "    assert not os.path.exists(args.output), \"Output file already exists.\"\n",
    "    torchaudio.save(args.output, output, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f27555-5f18-4207-8c08-783559044e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGETS = [\n",
    "#     \"Acoustic_guitar\",\n",
    "#     \"Applause\",\n",
    "#     \"Bark\",\n",
    "#     \"Bass_drum\",\n",
    "#     \"Burping_or_eructation\",\n",
    "#     \"Bus\",\n",
    "#     \"Cello\",\n",
    "#     \"Chime\",\n",
    "#     \"Clarinet\",\n",
    "#     \"Computer_keyboard\",\n",
    "#     \"Cough\",\n",
    "#     \"Cowbell\",\n",
    "#     \"Double_bass\",\n",
    "#     \"Drawer_open_or_close\",\n",
    "#     \"Electric_piano\",\n",
    "#     \"Fart\",\n",
    "#     \"Finger_snapping\",\n",
    "#     \"Fireworks\",\n",
    "#     \"Flute\",\n",
    "#     \"Glockenspiel\",\n",
    "#     \"Gong\",\n",
    "#     \"Gunshot_or_gunfire\",\n",
    "#     \"Harmonica\",\n",
    "#     \"Hi-hat\",\n",
    "#     \"Keys_jangling\",\n",
    "#     \"Knock\",\n",
    "#     \"Laughter\",\n",
    "#     \"Meow\",\n",
    "#     \"Microwave_oven\",\n",
    "#     \"Oboe\",\n",
    "#     \"Saxophone\",\n",
    "#     \"Scissors\",\n",
    "#     \"Shatter\",\n",
    "#     \"Snare_drum\",\n",
    "#     \"Squeak\",\n",
    "#     \"Tambourine\",\n",
    "#     \"Tearing\",\n",
    "#     \"Telephone\",\n",
    "#     \"Trumpet\",\n",
    "#     \"Violin_or_fiddle\",\n",
    "#     \"Writing\",\n",
    "# ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waveformer",
   "language": "python",
   "name": "waveformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
